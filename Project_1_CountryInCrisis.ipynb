{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>2013Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ND</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NE</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SD</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IA</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TX</td>\n",
       "      <td>2446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  2013Deaths\n",
       "0    ND          20\n",
       "1    NE         117\n",
       "2    SD          55\n",
       "3    IA         275\n",
       "4    TX        2446"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import source data files\n",
    "\n",
    "deaths_2013_2014 = pd.read_csv(\"raw_data/OD_2013_2014.csv\", thousands=',')\n",
    "deaths_2015 = pd.read_csv(\"raw_data/OD_2015.csv\", thousands=',')\n",
    "deaths_2016 = pd.read_csv(\"raw_data/OD_2016.csv\", thousands=',')\n",
    "deaths_2017 = pd.read_csv(\"raw_data/OD_2017.csv\", thousands=',')\n",
    "\n",
    "regions = pd.read_csv(\"raw_data/regions.csv\", thousands=',')\n",
    "\n",
    "# reduce dataframes to include only state and death statistic\n",
    "#############THESE ARE THE OVERDOSE BY STATE DATA FRAMES *********************\n",
    "deaths_2013_df = deaths_2013_2014[['State', '2013Number']]\n",
    "deaths_2013_df = deaths_2013_df.rename(index=str, columns={\"2013Number\": \"2013Deaths\"})\n",
    "# deaths_2013_df[\"2013Deaths\"] = pd.to_numeric(deaths_2013_df[\"2013Deaths\"])\n",
    "deaths_2014_df = deaths_2013_2014[['State', '2014Number']]\n",
    "deaths_2014_df = deaths_2014_df.rename(index=str, columns={\"2014Number\": \"2014Deaths\"})\n",
    "deaths_2015_df = deaths_2015[['State', 'Number']]\n",
    "deaths_2015_df = deaths_2015_df.rename(index=str, columns={\"Number\": \"2015Deaths\"})\n",
    "deaths_2016_df = deaths_2016[['State', 'number']]\n",
    "deaths_2016_df = deaths_2016_df.rename(index=str, columns={\"number\": \"2016Deaths\"})\n",
    "deaths_2017_df = deaths_2017[['State', 'number']]\n",
    "deaths_2017_df = deaths_2017_df.rename(index=str, columns={\"number\": \"2017Deaths\"})\n",
    "\n",
    "deaths_2013_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>2017_RX_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>107.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>61.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>105.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>39.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  2017_RX_rate\n",
       "0    AL         107.2\n",
       "1    AK          52.0\n",
       "2    AZ          61.2\n",
       "3    AR         105.4\n",
       "4    CA          39.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import perscription data\n",
    "rx_2013 = pd.read_csv(\"raw_data/RX_2013.csv\")\n",
    "rx_2014 = pd.read_csv(\"raw_data/RX_2014.csv\")\n",
    "rx_2015 = pd.read_csv(\"raw_data/RX_2015.csv\")\n",
    "rx_2016 = pd.read_csv(\"raw_data/RX_2016.csv\")\n",
    "rx_2017 = pd.read_csv(\"raw_data/RX_2017.csv\")\n",
    "\n",
    "# reduce dataframes to include only state and death statistic \n",
    "rx_2013_df = rx_2013[['State ABBR', '2013 Prescribing Rate']]\n",
    "rx_2013_df = rx_2013_df.rename(index=str, columns={\"State ABBR\": \"State\", \"2013 Prescribing Rate\": \"2013_RX_rate\"})\n",
    "rx_2014_df = rx_2014[['State ABBR', '2014 Prescribing Rate']]\n",
    "rx_2014_df = rx_2014_df.rename(index=str, columns={\"State ABBR\": \"State\", \"2014 Prescribing Rate\": \"2014_RX_rate\"})\n",
    "rx_2015_df = rx_2015[['State ABBR', '2015 Prescribing Rate']]\n",
    "rx_2015_df = rx_2015_df.rename(index=str, columns={\"State ABBR\": \"State\", \"2015 Prescribing Rate\": \"2015_RX_rate\"})\n",
    "rx_2016_df = rx_2016[['State ABBR', '2016 Prescribing Rate']]\n",
    "rx_2016_df = rx_2016_df.rename(index=str, columns={\"State ABBR\": \"State\", \"2016 Prescribing Rate\": \"2016_RX_rate\"})\n",
    "rx_2017_df = rx_2017[['Abbreviation', 'Year 2017']].drop([51], axis=0).reset_index(drop=True)\n",
    "rx_2017_df = rx_2017_df.rename(index=str, columns={\"Abbreviation\": \"State\", \"Year 2017\": \"2017_RX_rate\"})\n",
    "\n",
    "# drop last row in rx_2017 becuase it is a duplicate entry (WY)\n",
    "# rx_2017_df = rx_2017_df.drop([51], axis=0).reset_index()\n",
    "\n",
    "#######THESE ARE THE PERSCRIPTION BY STATE DATA FRAMES*******************\n",
    "# rx_2013_df\n",
    "# rx_2014_df\n",
    "# rx_2015_df\n",
    "# rx_2016_df\n",
    "# rx_2017_df\n",
    "\n",
    "\n",
    "rx_2017_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "No common columns to perform merge on. Merge options: left_on=None, right_on=None, left_index=False, right_index=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bc30447fd326>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m# merge regions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mpop_2010_2017_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpop_2010_2017_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[0mpop_2010_2017_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   6866\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6867\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6868\u001b[1;33m                      copy=copy, indicator=indicator, validate=validate)\n\u001b[0m\u001b[0;32m   6869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6870\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     45\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                          validate=validate)\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_specification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;31m# note this function has side effects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_validate_specification\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1031\u001b[0m                         \u001b[1;34m'left_index={lidx}, right_index={ridx}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m                         .format(lon=self.left_on, ron=self.right_on,\n\u001b[1;32m-> 1033\u001b[1;33m                                 lidx=self.left_index, ridx=self.right_index))\n\u001b[0m\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcommon_cols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                     raise MergeError(\"Data columns not unique: {common!r}\"\n",
      "\u001b[1;31mMergeError\u001b[0m: No common columns to perform merge on. Merge options: left_on=None, right_on=None, left_index=False, right_index=False"
     ]
    }
   ],
   "source": [
    "# import population data\n",
    "population2010_2017 = pd.read_csv(\"raw_data/Pop_2013-2017.csv\", thousands=',')\n",
    "# remove first two rows because they are insignificant to the dataframe\n",
    "population2010_2017_a = population2010_2017.drop([0,1,2,3,4,56,57,58,59,60,61,62], axis=0).reset_index(drop=True)\n",
    "# rename column headers\n",
    "population2010_2017_a = population2010_2017_a.rename(index=str, columns={\"Unnamed: 0\": \"State\", \"2013\": \"2013_Pop\", \"2014\": \"2014_Pop\", \"2015\": \"2015_Pop\", \"2016\": \"2016_Pop\", \"2017\": \"2017_Pop\"})\n",
    "# create dataframe with new column names\n",
    "pop_2010_2017_df = pd.DataFrame(population2010_2017_a)\n",
    "pop_2010_2017_df = pop_2010_2017_df.replace({'.Alabama': 'AL',\n",
    "                                             '.Alaska': 'AK', \n",
    "                                             '.Arizona': 'AZ',\n",
    "                                             '.Arkansas': 'AR',\n",
    "                                             '.California': 'CA',\n",
    "                                             '.Colorado': 'CO',\n",
    "                                             '.Connecticut': 'CT',\n",
    "                                             '.Delaware': 'DE',\n",
    "                                             '.District of Columbia': 'DC',\n",
    "                                             '.Florida': 'FL',\n",
    "                                             '.Georgia': 'GA',\n",
    "                                             '.Hawaii': 'HI',\n",
    "                                             '.Idaho': 'ID',\n",
    "                                             '.Illinois': 'IL',\n",
    "                                             '.Indiana': 'IN',\n",
    "                                             '.Iowa': 'IA',\n",
    "                                             '.Kansas': 'KS',\n",
    "                                             '.Kentucky': 'KY',\n",
    "                                             '.Louisiana':'LA',\n",
    "                                             '.Maine': 'ME',\n",
    "                                             '.Maryland':'MD',\n",
    "                                             '.Massachusetts':'MA',\n",
    "                                             '.Michigan':'MI',\n",
    "                                             '.Minnesota':'MN',\n",
    "                                             '.Mississippi':'MS',\n",
    "                                             '.Missouri':'MO',\n",
    "                                             '.Montana':'MT',\n",
    "                                             '.Nebraska':'NE',\n",
    "                                             '.Nevada':'NV',\n",
    "                                             '.New Hampshire':'NH',\n",
    "                                             '.New Jersey':'NJ',\n",
    "                                             '.New Mexico':'NM',\n",
    "                                             '.New York':'NY',\n",
    "                                             '.North Carolina':'NC',\n",
    "                                             '.North Dakota':'ND',\n",
    "                                             '.Ohio':'OH',\n",
    "                                             '.Oklahoma':'OK',\n",
    "                                             '.Oregon':'OR',\n",
    "                                             '.Pennsylvania':'PA',\n",
    "                                             '.Rhode Island':'RI',\n",
    "                                             '.South Carolina':'SC',\n",
    "                                             '.South Dakota':'SD',\n",
    "                                             '.Tennessee':'TN',\n",
    "                                             '.Texas':'TX',\n",
    "                                             '.Utah':'UT',\n",
    "                                             '.Vermont':'VT',\n",
    "                                             '.Virginia':'VA',\n",
    "                                             '.Washington':'WA',\n",
    "                                             '.West Virginia':'WV',\n",
    "                                             '.Wisconsin':'WI',\n",
    "                                             '.Wyoming':'WY'})\n",
    "######THIS IS THE POPULATION DATA FRAME******************************\n",
    "# pop_2010_2017_df\n",
    "\n",
    "# merge regions\n",
    "pop_2010_2017_df = pop_2010_2017_df.merge(regions)\n",
    "\n",
    "pop_2010_2017_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "No common columns to perform merge on. Merge options: left_on=None, right_on=None, left_index=False, right_index=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-38314ca7e4db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# merge 2013 tables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprd_13_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpop_2010_2017_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrx_2013_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeaths_2013_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# merge 2013-2014 tables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprd_14_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprd_13_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrx_2014_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeaths_2014_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   6866\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6867\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6868\u001b[1;33m                      copy=copy, indicator=indicator, validate=validate)\n\u001b[0m\u001b[0;32m   6869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6870\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     45\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                          validate=validate)\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_specification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;31m# note this function has side effects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_validate_specification\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1031\u001b[0m                         \u001b[1;34m'left_index={lidx}, right_index={ridx}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m                         .format(lon=self.left_on, ron=self.right_on,\n\u001b[1;32m-> 1033\u001b[1;33m                                 lidx=self.left_index, ridx=self.right_index))\n\u001b[0m\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcommon_cols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                     raise MergeError(\"Data columns not unique: {common!r}\"\n",
      "\u001b[1;31mMergeError\u001b[0m: No common columns to perform merge on. Merge options: left_on=None, right_on=None, left_index=False, right_index=False"
     ]
    }
   ],
   "source": [
    "# merge population_df, rx_dfs, and deaths_dfs (prd = population rx deaths)\n",
    "# prd_df = pop_2010_2017_df.merge(rx_2013_df).merge(deaths_2013_df).merge(rx_2014_df).merge(deaths_2014_df).merge(rx_2015_df).merge(deaths_2015_df).merge(rx_2016_df).merge(deaths_2016_df).merge(rx_2017_df).merge(deaths_2017_df)\n",
    "\n",
    "# merge 2013 tables\n",
    "prd_13_df = pop_2010_2017_df.merge(rx_2013_df).merge(deaths_2013_df)\n",
    "# merge 2013-2014 tables\n",
    "prd_14_df = prd_13_df.merge(rx_2014_df).merge(deaths_2014_df)\n",
    "# merge 2013-2015 tables\n",
    "prd_15_df = prd_14_df.merge(rx_2015_df).merge(deaths_2015_df)\n",
    "# merge 2013-2016 tables\n",
    "prd_16_df = prd_15_df.merge(rx_2016_df).merge(deaths_2016_df)\n",
    "# merge 2013-2017 tables\n",
    "prd_17_df = prd_16_df.merge(rx_2017_df).merge(deaths_2017_df)\n",
    "\n",
    "\n",
    "prd_17_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column locations and create the final consolidated dataframe called \"master_df\"\n",
    "master_df = pd.DataFrame(prd_17_df[['State','Region',\n",
    "                                    '2013_Pop','2013_RX_rate','2013Deaths',\n",
    "                                    '2014_Pop','2014_RX_rate','2014Deaths',\n",
    "                                    '2015_Pop','2015_RX_rate','2015Deaths',\n",
    "                                    '2016_Pop','2016_RX_rate','2016Deaths',\n",
    "                                    '2017_Pop','2017_RX_rate','2017Deaths']])\n",
    "\n",
    "# convert population column values to integers for downstream statistical analysis\n",
    "master_df['2013_Pop'] = master_df['2013_Pop'].apply(int)\n",
    "master_df['2014_Pop'] = master_df['2014_Pop'].apply(int)\n",
    "master_df['2015_Pop'] = master_df['2015_Pop'].apply(int)\n",
    "master_df['2016_Pop'] = master_df['2016_Pop'].apply(int)\n",
    "master_df['2017_Pop'] = master_df['2017_Pop'].apply(int)\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize deaths by dividing by 100,000\n",
    "master_df['2013Deaths'] = master_df['2013Deaths'] / (master_df['2013_Pop'] / 100000)\n",
    "master_df['2014Deaths'] = master_df['2014Deaths'] / (master_df['2014_Pop'] / 100000)\n",
    "master_df['2015Deaths'] = master_df['2015Deaths'] / (master_df['2015_Pop'] / 100000)\n",
    "master_df['2016Deaths'] = master_df['2016Deaths'] / (master_df['2016_Pop'] / 100000)\n",
    "master_df['2017Deaths'] = master_df['2017Deaths'] / (master_df['2017_Pop'] / 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset master dataframe into regional data frames by economic region\n",
    "southeast = master_df[master_df.Region == 'Southeast'].reset_index(drop=True)\n",
    "southwest = master_df[master_df.Region == 'Southwest'].reset_index(drop=True)\n",
    "farwest = master_df[master_df.Region == 'Far West'].reset_index(drop=True)\n",
    "rockmount = master_df[master_df.Region == 'Rocky Mountain'].reset_index(drop=True)\n",
    "plains = master_df[master_df.Region == 'Plains'].reset_index(drop=True)\n",
    "greatlakes = master_df[master_df.Region == 'Great Lakes'].reset_index(drop=True)\n",
    "mideast = master_df[master_df.Region == 'Mideast'].reset_index(drop=True)\n",
    "newengland = master_df[master_df.Region == 'New England'].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "newengland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create descriptive stats summary table\n",
    "\n",
    "master_range_max = master_df.max()\n",
    "master_range_min = master_df.min()\n",
    "master_mean = master_df.mean().apply(int)\n",
    "master_median = master_df.median().apply(int)\n",
    "master_stdev = master_df.std()\n",
    "master_var = master_df.var().apply(int)\n",
    "master_count = master_df.count()\n",
    "master_sum = master_df.sum()\n",
    "master_df.describe()\n",
    "# master_sum_stats_df = pd.DataFrame(master_df.describe())\n",
    "# master_sum_stats_df\n",
    "master_stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table of correlations\n",
    "master_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create odds ratios by region (odds of death from overdose from target region compared to all other regions)\n",
    "# calculate deaths by region, from 2013 through 2017\n",
    "deaths_southeast = southeast[['2013Deaths', '2014Deaths', '2015Deaths', '2016Deaths', '2017Deaths']].apply(sum)\n",
    "total_deaths_southeast = deaths_southeast.sum()\n",
    "\n",
    "deaths_southwest = southwest[['2013Deaths', '2014Deaths', '2015Deaths', '2016Deaths', '2017Deaths']].apply(sum)\n",
    "total_deaths_southwest = deaths_southwest.sum()\n",
    "\n",
    "deaths_farwest = farwest[['2013Deaths', '2014Deaths', '2015Deaths', '2016Deaths', '2017Deaths']].apply(sum)\n",
    "total_deaths_farwest = deaths_farwest.sum()\n",
    "\n",
    "deaths_rockmount = rockmount[['2013Deaths', '2014Deaths', '2015Deaths', '2016Deaths', '2017Deaths']].apply(sum)\n",
    "total_deaths_rockmount = deaths_rockmount.sum()\n",
    "\n",
    "deaths_plains = plains[['2013Deaths', '2014Deaths', '2015Deaths', '2016Deaths', '2017Deaths']].apply(sum)\n",
    "total_deaths_plains = deaths_plains.sum()\n",
    "\n",
    "deaths_greatlakes = greatlakes[['2013Deaths', '2014Deaths', '2015Deaths', '2016Deaths', '2017Deaths']].apply(sum)\n",
    "total_deaths_greatlakes = deaths_greatlakes.sum()\n",
    "\n",
    "deaths_mideast = mideast[['2013Deaths', '2014Deaths', '2015Deaths', '2016Deaths', '2017Deaths']].apply(sum)\n",
    "total_deaths_mideast = deaths_mideast.sum()\n",
    "\n",
    "deaths_newengland = newengland[['2013Deaths', '2014Deaths', '2015Deaths', '2016Deaths', '2017Deaths']].apply(sum)\n",
    "total_deaths_newengland = deaths_newengland.sum()\n",
    "\n",
    "# calculate total population by region, from 2013 through 2017 \n",
    "pop_southeast = southeast[['2013_Pop', '2014_Pop','2015_Pop','2016_Pop','2017_Pop',]].apply(sum)\n",
    "total_pop_southeast = pop_southeast.sum()\n",
    "\n",
    "pop_southwest = southwest[['2013_Pop', '2014_Pop','2015_Pop','2016_Pop','2017_Pop',]].apply(sum)\n",
    "total_pop_southwest = pop_southwest.sum()\n",
    "\n",
    "pop_farwest = farwest[['2013_Pop', '2014_Pop','2015_Pop','2016_Pop','2017_Pop',]].apply(sum)\n",
    "total_pop_farwest = pop_farwest.sum()\n",
    "\n",
    "pop_rockmount = rockmount[['2013_Pop', '2014_Pop','2015_Pop','2016_Pop','2017_Pop',]].apply(sum)\n",
    "total_pop_rockmount = pop_rockmount.sum()\n",
    "\n",
    "pop_plains = plains[['2013_Pop', '2014_Pop','2015_Pop','2016_Pop','2017_Pop',]].apply(sum)\n",
    "total_pop_plains = pop_plains.sum()\n",
    "\n",
    "pop_greatlakes = greatlakes[['2013_Pop', '2014_Pop','2015_Pop','2016_Pop','2017_Pop',]].apply(sum)\n",
    "total_pop_greatlakes = pop_greatlakes.sum()\n",
    "\n",
    "pop_mideast = mideast[['2013_Pop', '2014_Pop','2015_Pop','2016_Pop','2017_Pop',]].apply(sum)\n",
    "total_pop_mideast = pop_mideast.sum()\n",
    "\n",
    "pop_newengland = newengland[['2013_Pop', '2014_Pop','2015_Pop','2016_Pop','2017_Pop',]].apply(sum)\n",
    "total_pop_newengland = pop_newengland.sum()\n",
    "\n",
    "# calculate combined population for all regions, for entire period of analysis\n",
    "combined_pop = total_pop_southwest + total_pop_southeast + total_pop_farwest + total_pop_rockmount + total_pop_plains + total_pop_greatlakes + total_pop_mideast + total_pop_newengland\n",
    "combined_pop\n",
    "\n",
    "# calculate nots for each region in the odds table\n",
    "death_not_southeast = total_pop_southeast - total_deaths_southeast\n",
    "death_not_southwest = total_pop_southwest - total_deaths_southwest\n",
    "death_not_farwest = total_pop_farwest - total_deaths_farwest\n",
    "death_not_rockmount = total_pop_rockmount - total_deaths_rockmount\n",
    "death_not_plains = total_pop_plains - total_deaths_plains\n",
    "death_not_greatlakes = total_pop_greatlakes - total_deaths_greatlakes\n",
    "death_not_mideast = total_pop_mideast - total_deaths_mideast\n",
    "death_not_newengland = total_pop_newengland - total_deaths_newengland\n",
    "\n",
    "# calculate not nots for all other regions in odds table\n",
    "\n",
    "combined_not_deaths = death_not_southeast + death_not_southwest + death_not_farwest + death_not_rockmount + death_not_plains + death_not_greatlakes + death_not_mideast + death_not_newengland\n",
    "\n",
    "# calculate combined deaths\n",
    "\n",
    "combined_deaths = total_deaths_southeast + total_deaths_southwest + total_deaths_farwest + total_deaths_rockmount + total_deaths_plains + total_deaths_greatlakes + total_deaths_mideast + total_deaths_newengland\n",
    "combined_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create odds ratio table by target region, compared to all other regions for deaths during 2013 - 2017 time period; algorithm is: \n",
    "# odds_x = (total_deaths_x * (combined_not_deaths - death_not_x) / (death_not_x * combined_deaths - total_deaths_x) )\n",
    "odds_southeast = (total_deaths_southeast * (combined_not_deaths - death_not_southeast) / (death_not_southeast * combined_deaths - total_deaths_southeast) )\n",
    "odds_southwest = (total_deaths_southwest * (combined_not_deaths - death_not_southwest) / (death_not_southwest * combined_deaths - total_deaths_southwest) )\n",
    "odds_farwest = (total_deaths_farwest * (combined_not_deaths - death_not_farwest) / (death_not_farwest * combined_deaths - total_deaths_farwest) )\n",
    "odds_rockmount = (total_deaths_rockmount * (combined_not_deaths - death_not_rockmount) / (death_not_rockmount * combined_deaths - total_deaths_rockmount) )\n",
    "odds_plains = (total_deaths_plains * (combined_not_deaths - death_not_plains) / (death_not_plains * combined_deaths - total_deaths_plains) )\n",
    "odds_greatlakes = (total_deaths_greatlakes * (combined_not_deaths - death_not_greatlakes) / (death_not_greatlakes * combined_deaths - total_deaths_greatlakes) )\n",
    "odds_mideast = (total_deaths_mideast * (combined_not_deaths - death_not_mideast) / (death_not_mideast * combined_deaths - total_deaths_mideast) )\n",
    "odds_newengland = (total_deaths_newengland * (combined_not_deaths - death_not_newengland) / (death_not_newengland * combined_deaths - total_deaths_newengland) )\n",
    "\n",
    "odds_ratios = [odds_southeast, odds_southwest, odds_farwest, odds_rockmount, odds_plains, odds_greatlakes, odds_mideast, odds_newengland]\n",
    "odds_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_ratio_df = pd.DataFrame({\n",
    "    'Region': ['Southeast', 'Southwest', 'Far West', 'Rockies', 'Plains', 'Great Lakes', 'Mideast', 'New England'],\n",
    "    'Odds for Death': [odds_southeast, odds_southwest, odds_farwest, odds_rockmount, odds_plains, odds_greatlakes, odds_mideast, odds_newengland]\n",
    "})\n",
    "odds_ratio_df = odds_ratio_df.sort_values(['Odds for Death'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "odds_ratio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a (multiple) bar graph of deaths and rx totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
